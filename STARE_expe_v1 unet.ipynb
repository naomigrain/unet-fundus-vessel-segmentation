{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjGxDpxUdn6/aj/WLu/KFG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"4OJjwQsSEz3t","executionInfo":{"status":"ok","timestamp":1676477222313,"user_tz":-420,"elapsed":4164,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"outputs":[],"source":["import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import sklearn.metrics as sm\n","import tensorflow as tf\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from tensorflow.keras import backend as keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import scipy.misc as sc"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k6r1zhFKHPhK","executionInfo":{"status":"ok","timestamp":1676477259842,"user_tz":-420,"elapsed":20627,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}},"outputId":"b0a9030d-3b11-426b-8ca0-ca6890f2aad8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["PATH = '/content/drive/MyDrive/STARE/'\n","TRAIN_PATH = PATH+'train/'\n","TRAIN_AUG_PATH = TRAIN_PATH+'aug/'\n","TRAIN_IMAGE_FOLDER = 'images'\n","TRAIN_MASK_FOLDER = 'GT'\n","IMAGE_PREFIX = 'image'\n","MASK_PREFIX = 'mask'\n","TRAIN_TARGET_SIZE = (512,512)\n","TRAIN_BATCH_SIZE = 3\n","SEED = 1\n","TEST_PATH = PATH+'test/'\n","TEST_IMAGE_PATH = TEST_PATH+'images/'\n","SAVE_TEST_IMAGE_PATH = TEST_PATH+'pred/'\n","TEST_TARGET_SIZE = (512,512)"],"metadata":{"id":"75bKHmHhHRzN","executionInfo":{"status":"ok","timestamp":1676477262460,"user_tz":-420,"elapsed":495,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def adjustData(img,mask,flag_multi_class,num_class):\n","    if(flag_multi_class):\n","        img /= 255\n","        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","        new_mask = np.zeros(mask.shape + (num_class,))\n","        for i in range(num_class):\n","            new_mask[mask == i,i] = 1\n","        new_mask = np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n","        mask = new_mask\n","    elif(np.max(img) > 1):\n","        img = img / 255\n","        mask = mask /255\n","        mask[mask > 0.5] = 1\n","        mask[mask <= 0.5] = 0\n","    return (img,mask)\n","\n","def trainGenerator(aug_dict, flag_multi_class = False, num_class = 2):\n","    image_datagen = ImageDataGenerator(**aug_dict)\n","    mask_datagen = ImageDataGenerator(**aug_dict)\n","    image_generator = image_datagen.flow_from_directory(\n","        TRAIN_PATH,\n","        classes = [TRAIN_IMAGE_FOLDER],\n","        class_mode = None,\n","        color_mode = 'grayscale',\n","        target_size = TRAIN_TARGET_SIZE,\n","        batch_size = TRAIN_BATCH_SIZE,\n","        save_to_dir = TRAIN_AUG_PATH,\n","        save_prefix  = IMAGE_PREFIX,\n","        seed = SEED)\n","    mask_generator = mask_datagen.flow_from_directory(\n","        TRAIN_PATH,\n","        classes = [TRAIN_MASK_FOLDER],\n","        class_mode = None,\n","        color_mode = 'grayscale',\n","        target_size = TRAIN_TARGET_SIZE,\n","        batch_size = TRAIN_BATCH_SIZE,\n","        save_to_dir = TRAIN_AUG_PATH,\n","        save_prefix  = MASK_PREFIX,\n","        seed = SEED)\n","    train_generator = zip(image_generator, mask_generator)\n","    for (img,mask) in train_generator:\n","        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n","        yield (img,mask)"],"metadata":{"id":"G67N1WmdH65Z","executionInfo":{"status":"ok","timestamp":1676477270448,"user_tz":-420,"elapsed":363,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_gen_args = dict(rotation_range=0.3,\n","                    width_shift_range=0.05,\n","                    height_shift_range=0.05,\n","                    shear_range=0.1,\n","                    # zoom_range=[0.7,1],\n","                    horizontal_flip=True,\n","                    fill_mode='nearest')\n","\n","if not os.path.exists(TRAIN_PATH+'aug'):\n","    os.makedirs(TRAIN_PATH+'aug')\n","      \n","data_gen = trainGenerator(aug_dict=data_gen_args)"],"metadata":{"id":"q6O250YFIyUA","executionInfo":{"status":"ok","timestamp":1676477540535,"user_tz":-420,"elapsed":380,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def unet(pretrained_weights = None,input_size = (512,512,1)):\n","    inputs = tf.keras.Input(shape=input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(64, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2,padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(128, 3, activation = 'relu', dilation_rate=2, padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    drop4 = Dropout(0.5)(conv4, training=True)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    drop5 = Dropout(0.5)(conv5, training=True)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    \n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    \n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    \n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","   \n","    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","    \n","\n","    if(pretrained_weights):\n","    \tmodel=keras.models.load_model(pretrained_weights)\n","\n","    return model"],"metadata":{"id":"Hmi6maTVI08r","executionInfo":{"status":"ok","timestamp":1676477543447,"user_tz":-420,"elapsed":351,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = unet()\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet_STARE.hdf5', monitor='loss', verbose=1, save_best_only=True)\n","callbacks = [ model_checkpoint ]\n","history = model.fit(\n","    data_gen,\n","    steps_per_epoch=10,\n","    epochs=80,\n","    verbose=0,\n","    callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJ11qU9HJacL","executionInfo":{"status":"ok","timestamp":1676478481490,"user_tz":-420,"elapsed":934454,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}},"outputId":"86df1df9-7505-4f2a-99cb-ae3e923a995e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Found 10 images belonging to 1 classes.\n","Found 10 images belonging to 1 classes.\n","\n","Epoch 1: loss improved from inf to 0.66791, saving model to unet_STARE.hdf5\n","\n","Epoch 2: loss did not improve from 0.66791\n","\n","Epoch 3: loss did not improve from 0.66791\n","\n","Epoch 4: loss did not improve from 0.66791\n","\n","Epoch 5: loss did not improve from 0.66791\n","\n","Epoch 6: loss did not improve from 0.66791\n","\n","Epoch 7: loss improved from 0.66791 to 0.66672, saving model to unet_STARE.hdf5\n","\n","Epoch 8: loss improved from 0.66672 to 0.66277, saving model to unet_STARE.hdf5\n","\n","Epoch 9: loss improved from 0.66277 to 0.65868, saving model to unet_STARE.hdf5\n","\n","Epoch 10: loss improved from 0.65868 to 0.65482, saving model to unet_STARE.hdf5\n","\n","Epoch 11: loss improved from 0.65482 to 0.65082, saving model to unet_STARE.hdf5\n","\n","Epoch 12: loss improved from 0.65082 to 0.64697, saving model to unet_STARE.hdf5\n","\n","Epoch 13: loss improved from 0.64697 to 0.64304, saving model to unet_STARE.hdf5\n","\n","Epoch 14: loss improved from 0.64304 to 0.63935, saving model to unet_STARE.hdf5\n","\n","Epoch 15: loss improved from 0.63935 to 0.63554, saving model to unet_STARE.hdf5\n","\n","Epoch 16: loss improved from 0.63554 to 0.63170, saving model to unet_STARE.hdf5\n","\n","Epoch 17: loss improved from 0.63170 to 0.62803, saving model to unet_STARE.hdf5\n","\n","Epoch 18: loss improved from 0.62803 to 0.62438, saving model to unet_STARE.hdf5\n","\n","Epoch 19: loss improved from 0.62438 to 0.62073, saving model to unet_STARE.hdf5\n","\n","Epoch 20: loss improved from 0.62073 to 0.61713, saving model to unet_STARE.hdf5\n","\n","Epoch 21: loss improved from 0.61713 to 0.61372, saving model to unet_STARE.hdf5\n","\n","Epoch 22: loss improved from 0.61372 to 0.60987, saving model to unet_STARE.hdf5\n","\n","Epoch 23: loss improved from 0.60987 to 0.60644, saving model to unet_STARE.hdf5\n","\n","Epoch 24: loss improved from 0.60644 to 0.60312, saving model to unet_STARE.hdf5\n","\n","Epoch 25: loss improved from 0.60312 to 0.59948, saving model to unet_STARE.hdf5\n","\n","Epoch 26: loss improved from 0.59948 to 0.59633, saving model to unet_STARE.hdf5\n","\n","Epoch 27: loss improved from 0.59633 to 0.59266, saving model to unet_STARE.hdf5\n","\n","Epoch 28: loss improved from 0.59266 to 0.58965, saving model to unet_STARE.hdf5\n","\n","Epoch 29: loss improved from 0.58965 to 0.58628, saving model to unet_STARE.hdf5\n","\n","Epoch 30: loss improved from 0.58628 to 0.58281, saving model to unet_STARE.hdf5\n","\n","Epoch 31: loss improved from 0.58281 to 0.57953, saving model to unet_STARE.hdf5\n","\n","Epoch 32: loss improved from 0.57953 to 0.57663, saving model to unet_STARE.hdf5\n","\n","Epoch 33: loss improved from 0.57663 to 0.57330, saving model to unet_STARE.hdf5\n","\n","Epoch 34: loss improved from 0.57330 to 0.57006, saving model to unet_STARE.hdf5\n","\n","Epoch 35: loss improved from 0.57006 to 0.56736, saving model to unet_STARE.hdf5\n","\n","Epoch 36: loss improved from 0.56736 to 0.56354, saving model to unet_STARE.hdf5\n","\n","Epoch 37: loss improved from 0.56354 to 0.56067, saving model to unet_STARE.hdf5\n","\n","Epoch 38: loss improved from 0.56067 to 0.55793, saving model to unet_STARE.hdf5\n","\n","Epoch 39: loss improved from 0.55793 to 0.55467, saving model to unet_STARE.hdf5\n","\n","Epoch 40: loss improved from 0.55467 to 0.55199, saving model to unet_STARE.hdf5\n","\n","Epoch 41: loss improved from 0.55199 to 0.54848, saving model to unet_STARE.hdf5\n","\n","Epoch 42: loss improved from 0.54848 to 0.54624, saving model to unet_STARE.hdf5\n","\n","Epoch 43: loss improved from 0.54624 to 0.54306, saving model to unet_STARE.hdf5\n","\n","Epoch 44: loss improved from 0.54306 to 0.54016, saving model to unet_STARE.hdf5\n","\n","Epoch 45: loss improved from 0.54016 to 0.53746, saving model to unet_STARE.hdf5\n","\n","Epoch 46: loss improved from 0.53746 to 0.53429, saving model to unet_STARE.hdf5\n","\n","Epoch 47: loss improved from 0.53429 to 0.53138, saving model to unet_STARE.hdf5\n","\n","Epoch 48: loss improved from 0.53138 to 0.52932, saving model to unet_STARE.hdf5\n","\n","Epoch 49: loss improved from 0.52932 to 0.52615, saving model to unet_STARE.hdf5\n","\n","Epoch 50: loss improved from 0.52615 to 0.52362, saving model to unet_STARE.hdf5\n","\n","Epoch 51: loss improved from 0.52362 to 0.52043, saving model to unet_STARE.hdf5\n","\n","Epoch 52: loss improved from 0.52043 to 0.51856, saving model to unet_STARE.hdf5\n","\n","Epoch 53: loss improved from 0.51856 to 0.51565, saving model to unet_STARE.hdf5\n","\n","Epoch 54: loss improved from 0.51565 to 0.51289, saving model to unet_STARE.hdf5\n","\n","Epoch 55: loss improved from 0.51289 to 0.51007, saving model to unet_STARE.hdf5\n","\n","Epoch 56: loss improved from 0.51007 to 0.50801, saving model to unet_STARE.hdf5\n","\n","Epoch 57: loss improved from 0.50801 to 0.50531, saving model to unet_STARE.hdf5\n","\n","Epoch 58: loss improved from 0.50531 to 0.50270, saving model to unet_STARE.hdf5\n","\n","Epoch 59: loss improved from 0.50270 to 0.50048, saving model to unet_STARE.hdf5\n","\n","Epoch 60: loss improved from 0.50048 to 0.49771, saving model to unet_STARE.hdf5\n","\n","Epoch 61: loss improved from 0.49771 to 0.49604, saving model to unet_STARE.hdf5\n","\n","Epoch 62: loss improved from 0.49604 to 0.49233, saving model to unet_STARE.hdf5\n","\n","Epoch 63: loss improved from 0.49233 to 0.49104, saving model to unet_STARE.hdf5\n","\n","Epoch 64: loss improved from 0.49104 to 0.48794, saving model to unet_STARE.hdf5\n","\n","Epoch 65: loss improved from 0.48794 to 0.48542, saving model to unet_STARE.hdf5\n","\n","Epoch 66: loss improved from 0.48542 to 0.48424, saving model to unet_STARE.hdf5\n","\n","Epoch 67: loss improved from 0.48424 to 0.48114, saving model to unet_STARE.hdf5\n","\n","Epoch 68: loss improved from 0.48114 to 0.47922, saving model to unet_STARE.hdf5\n","\n","Epoch 69: loss improved from 0.47922 to 0.47733, saving model to unet_STARE.hdf5\n","\n","Epoch 70: loss improved from 0.47733 to 0.47406, saving model to unet_STARE.hdf5\n","\n","Epoch 71: loss improved from 0.47406 to 0.47217, saving model to unet_STARE.hdf5\n","\n","Epoch 72: loss improved from 0.47217 to 0.47041, saving model to unet_STARE.hdf5\n","\n","Epoch 73: loss improved from 0.47041 to 0.46804, saving model to unet_STARE.hdf5\n","\n","Epoch 74: loss improved from 0.46804 to 0.46594, saving model to unet_STARE.hdf5\n","\n","Epoch 75: loss improved from 0.46594 to 0.46399, saving model to unet_STARE.hdf5\n","\n","Epoch 76: loss improved from 0.46399 to 0.46157, saving model to unet_STARE.hdf5\n","\n","Epoch 77: loss improved from 0.46157 to 0.45996, saving model to unet_STARE.hdf5\n","\n","Epoch 78: loss improved from 0.45996 to 0.45727, saving model to unet_STARE.hdf5\n","\n","Epoch 79: loss improved from 0.45727 to 0.45592, saving model to unet_STARE.hdf5\n","\n","Epoch 80: loss improved from 0.45592 to 0.45327, saving model to unet_STARE.hdf5\n"]}]},{"cell_type":"markdown","source":["[GPU]\n","start aug: 11.16\n","train: 15 menit"],"metadata":{"id":"M5_C7V3BI_Rd"}},{"cell_type":"code","source":["acc = history.history['accuracy']\n","loss = history.history['loss']\n","\n","max_acc = max(acc)\n","max_acc_i = acc.index(max_acc)\n","loss_at_max_acc = loss[max_acc_i]\n","\n","print('acc:', max_acc, 'loss:', loss_at_max_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KDjLbEhzNEii","executionInfo":{"status":"ok","timestamp":1676478735131,"user_tz":-420,"elapsed":394,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}},"outputId":"35bef02c-fa4e-45d7-d5e5-18eda8f9530a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["acc: 0.9262034296989441 loss: 0.4923255741596222\n"]}]},{"cell_type":"markdown","source":["14-02-2023; 23:40 <br>\n","acc: 0.9706441164016724 loss: 0.09779315441846848 <br><br>\n","\n","15-02-2023; 01:53 <br>\n","acc: 0.9781307578086853 loss: 0.06890685111284256 <br>\n","change: remove zoom scale <br><br>\n","\n","15-02-2023; 10:16 <br>\n","acc: 0.9769975543022156 loss: 0.07307402044534683 <br><br>\n","\n","15-02-2023; 23:32 <br>\n","acc: 0.9262034296989441 loss: 0.4923255741596222 <br><br>"],"metadata":{"id":"Mje4nO2tzAdq"}},{"cell_type":"code","source":["acc = history.history['accuracy']\n","loss = history.history['loss']\n","\n","max_acc = max(acc)\n","max_acc_i = acc.index(max_acc)\n","loss_at_max_acc = loss[max_acc_i]\n","\n","print('acc:', max_acc, 'loss:', loss_at_max_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676478743061,"user_tz":-420,"elapsed":364,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}},"outputId":"a7da8e8f-d8e6-40f8-f8aa-a7d7b9b3f916","id":"NiD1MTueE2Jm"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["acc: 0.9262034296989441 loss: 0.4923255741596222\n"]}]},{"cell_type":"code","source":["def testGenerator(as_gray = True):\n","    files=sorted(os.listdir(TEST_IMAGE_PATH))\n","    num_image=len(files)\n","    for i in range(num_image):\n","        img = io.imread(os.path.join(TEST_IMAGE_PATH,files[i]),as_gray = as_gray)\n","        print(files[i])\n","        img = trans.resize(img,TEST_TARGET_SIZE)\n","        img = np.reshape(img,img.shape+(1,))\n","        img = np.reshape(img,(1,)+img.shape)\n","        yield img"],"metadata":{"id":"Xk2oXzs8NvUx","executionInfo":{"status":"ok","timestamp":1676478749163,"user_tz":-420,"elapsed":353,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def labelVisualize(num_class,color_dict,img):\n","    img = img[:,:,0] if len(img.shape) == 3 else img\n","    img_out = np.zeros(img.shape + (3,))\n","    for i in range(num_class):\n","        img_out[img == i] = color_dict[i]\n","      \n","    return img_out\n","\n","def saveResult(npyfile):\n","    files=os.listdir(TEST_IMAGE_PATH)\n","    \n","    for i,item in enumerate(npyfile):\n","        img = item[:,:,0]\n","        img[img>0.1]=1\n","        img[img<=0.1]=0\n","        io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","\n","if not os.path.exists(SAVE_TEST_IMAGE_PATH):\n","    os.makedirs(SAVE_TEST_IMAGE_PATH)"],"metadata":{"id":"1At3uRQiN8Nc","executionInfo":{"status":"ok","timestamp":1676478751358,"user_tz":-420,"elapsed":349,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["n_i = len(os.listdir(TEST_IMAGE_PATH))\n","test_gen = testGenerator()\n","results = model.predict_generator(test_gen,n_i,verbose=1)\n","saveResult(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yEarfTAnNtJJ","executionInfo":{"status":"ok","timestamp":1676478759642,"user_tz":-420,"elapsed":5639,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}},"outputId":"481efb14-b024-4ec2-c1ed-f927b921ffcd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-046c9d728f71>:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  results = model.predict_generator(test_gen,n_i,verbose=1)\n"]},{"output_type":"stream","name":"stdout","text":["im0162.ppm\n"," 1/10 [==>...........................] - ETA: 3sim0163.ppm\n"," 2/10 [=====>........................] - ETA: 3sim0235.ppm\n"," 3/10 [========>.....................] - ETA: 3sim0236.ppm\n"," 4/10 [===========>..................] - ETA: 3sim0239.ppm\n"," 5/10 [==============>...............] - ETA: 2sim0240.ppm\n"," 6/10 [=================>............] - ETA: 2sim0255.ppm\n"," 7/10 [====================>.........] - ETA: 1sim0291.ppm\n"," 8/10 [=======================>......] - ETA: 0sim0319.ppm\n"," 9/10 [==========================>...] - ETA: 0sim0324.ppm\n","10/10 [==============================] - 5s 472ms/step\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0291.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0163.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0235.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0162.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0236.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0255.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0240.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0239.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0324.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n","<ipython-input-11-f97644e6b6be>:16: UserWarning: /content/drive/MyDrive/STARE/test/pred/im0319.ppm_predict.png is a low contrast image\n","  io.imsave(os.path.join(SAVE_TEST_IMAGE_PATH, files[i]+'_predict.png'),img)\n","WARNING:imageio:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"]}]},{"cell_type":"code","source":["def get_confusion_matrix_elements(groundtruth_list, predicted_list):\n","    tn, fp, fn, tp = sm.confusion_matrix(groundtruth_list, predicted_list,labels=[0,1]).ravel()\n","    tn, fp, fn, tp = np.float64(tn), np.float64(fp), np.float64(fn), np.float64(tp)\n","\n","    return tn, fp, fn, tp\n","\n","def get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list):\n","    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n","    \n","    total = tp + fp + fn + tn\n","    accuracy = (tp + tn) / total\n","    prec = tp/(tp+fp)\n","    rec = tp/(tp+fn)\n","    IoU = tp/(tp+fp+fn)\n","    \n","    return prec,rec,IoU,accuracy\n","\n","def get_f1_score(groundtruth_list, predicted_list):\n","    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n","    \n","    f1_score = (2 * tp) / ((2 * tp) + fp + fn)\n","\n","    return f1_score\n","\n","def get_validation_metrics(groundtruth,predicted):   \n","    u,v = np.shape(groundtruth)\n","    groundtruth_list = np.reshape(groundtruth,(u*v,))\n","    predicted_list = np.reshape(predicted,(u*v,))\n","    prec,rec,IoU,acc = get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list)\n","    f1_score = get_f1_score(groundtruth_list, predicted_list)\n","\n","    return prec,rec,IoU,acc,f1_score\n","\n","def evalResult(gth_path,npyfile,target_size=(512,512),flag_multi_class = False,num_class = 2):\n","    files=sorted(os.listdir(gth_path))\n","    print(files)\n","    prec = 0\n","    rec = 0\n","    acc = 0\n","    IoU = 0\n","    f1_score=0\n","    for i,item in enumerate(npyfile):\n","        img = item[:,:,0]\n","        gth = io.imread(os.path.join(gth_path,files[i]))\n","        gth = trans.resize(gth,target_size)\n","        img1=np.array(((img - np.min(img))/np.ptp(img))>0.1).astype(float)\n","        gth1=np.array(((gth - np.min(gth))/np.ptp(gth))>0.1).astype(float)\n","        p,r,I,a,f=get_validation_metrics(gth1,img1)\n","        prec = prec+p\n","        rec = rec+r\n","        acc = acc+a\n","        IoU = IoU+I\n","        f1_score = f1_score+f\n","    print(\"Precision=\",prec/(i+1), \"Recall=\",rec/(i+1), \"IoU=\",IoU/(i+1), \"acc=\",acc/(i+1), \"F1=\",f1_score/(i+1))    "],"metadata":{"id":"7oEv5laHbUDh","executionInfo":{"status":"ok","timestamp":1676478790330,"user_tz":-420,"elapsed":6,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["gt_path = TEST_PATH + 'GT/'\n","evalResult(gt_path,results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"byrJmAYQb5vX","executionInfo":{"status":"ok","timestamp":1676478801763,"user_tz":-420,"elapsed":4688,"user":{"displayName":"Lost Gatos","userId":"15945444398701474778"}},"outputId":"c1f7a173-b57e-4ada-f018-67cb87717875"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["['im0162.ah.ppm', 'im0163.ah.ppm', 'im0235.ah.ppm', 'im0236.ah.ppm', 'im0239.ah.ppm', 'im0240.ah.ppm', 'im0255.ah.ppm', 'im0291.ah.ppm', 'im0319.ah.ppm', 'im0324.ah.ppm']\n","Precision= 0.09468648790927088 Recall= 1.0 IoU= 0.09468648790927088 acc= 0.09468994140625 F1= 0.17229373847296356\n"]}]},{"cell_type":"markdown","source":["### Predicted\n","Precision= 0.7486418535745212 Recall= 0.8802602326917179 IoU= 0.6784592658474139 acc= 0.9618434906005859 F1= 0.8066515398308723 \n","\n","<b>15-02-2023; 10:30</b> \n","Precision= 0.6528929903566489 Recall= 0.902777067006806 IoU= 0.6070497388289681 acc= 0.9461292266845703 F1= 0.7534104948419812\n","\n","<b>15-02-2023; 22:33</b> \n","Precision= 0.09468648790927088 Recall= 1.0 IoU= 0.09468648790927088 acc= 0.09468994140625 F1= 0.17229373847296356"],"metadata":{"id":"jEQo1J7scMJ2"}}]}